import os
import glob
import re
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

ANALYSIS_DIR = r"d:\pyprojects\distribute\data\analysis"
OUTPUT_DIR = r"d:\pyprojects\distribute\data\conclusion"

sns.set_style("whitegrid")
plt.rcParams['font.sans-serif'] = ['SimHei', 'Arial Unicode MS']
plt.rcParams['axes.unicode_minus'] = False

def parse_lag_from_name(dir_name):
    """
    ä»ç›®å½•åè§£æ lag å€¼ã€‚
    ä¾‹å¦‚: 
    '3p0.5klag-all-data-trace_P3' -> 0.5
    'slide21k-1.5klag_Sliding_SZ2000_SL1000_P3' -> 1.5
    '3p2klag-...' -> 2.0
    """
    # åŒ¹é… æ•°å­—+klag
    match = re.search(r"(\d+(\.\d+)?)klag", dir_name)
    if match:
        return float(match.group(1))
    return None

def analyze_aggregation():
    print(f"ğŸš€ å¼€å§‹èšåˆåˆ†æ...")
    os.makedirs(OUTPUT_DIR, exist_ok=True)
    
    # å¯»æ‰¾æ‰€æœ‰çš„ summary.txt
    summary_files = glob.glob(os.path.join(ANALYSIS_DIR, "*", "summary.txt"))
    
    data = []
    
    for summary_file in summary_files:
        dir_name = os.path.basename(os.path.dirname(summary_file))
        lag = parse_lag_from_name(dir_name)
        
        if lag is None:
            print(f"âš ï¸ æ— æ³•ä» {dir_name} è§£æ Lagï¼Œè·³è¿‡ã€‚")
            continue
            
        # è¯»å– metrics csv è·å–æœ€ç»ˆçš„ç´¯ç§¯ä¸¢å¼ƒç‡
        # (è™½ç„¶ summary.txt ä¹Ÿæœ‰ï¼Œä½† metrics.csv æ›´æ–¹ä¾¿è¯»å–æœ€åä¸€è¡Œ)
        # æˆ–è€…ä» summary.txt è¯»
        # ç”¨ summary.txt æ¯”è¾ƒç¨³ï¼Œå› ä¸ºæ˜¯æœ€åç”Ÿæˆçš„
        drop_rate = 0.0
        with open(summary_file, 'r', encoding='utf-8') as f:
            content = f.read()
            # æŸ¥æ‰¾ "æ€»ä¸¢å¼ƒç‡: 4.00%"
            # æŸ¥æ‰¾ "æ€»ä¸¢å¼ƒç‡: 4.00%"
            match_drop = re.search(r"æ€»ä¸¢å¼ƒç‡:\s*([\d\.]+)%", content)
            if match_drop:
                drop_rate = float(match_drop.group(1)) / 100.0
            else:
                print(f"âš ï¸ ä» {summary_file} æ— æ³•è§£æä¸¢å¼ƒç‡")
                drop_rate = 0.0
            
            # æŸ¥æ‰¾ "å¹³å‡å¤„ç†å»¶è¿Ÿ: 0.1234 s"
            match_latency = re.search(r"å¹³å‡å¤„ç†å»¶è¿Ÿ:\s*([\d\.]+)\s*s", content)
            if match_latency:
                avg_latency = float(match_latency.group(1))
            else:
                print(f"âš ï¸ ä» {summary_file} æ— æ³•è§£æå»¶è¿Ÿ")
                avg_latency = 0.0

        # åŒºåˆ†å®éªŒç±»å‹
        experiment_type = "Unknown"
        if "slide21k" in dir_name:
            experiment_type = "Sliding Window"
        elif "3p" in dir_name or "Tumbling" in dir_name:
            experiment_type = "Tumbling Window"
        else:
            experiment_type = "Other"
            
        data.append({
            "Experiment": dir_name,
            "Lag": lag,
            "DropRate": drop_rate,
            "AvgLatency": avg_latency,
            "Type": experiment_type
        })
    
    if not data:
        print("âŒ æ²¡æœ‰æ”¶é›†åˆ°æ•°æ®ï¼")
        return
        
    df = pd.DataFrame(data)
    df = df.sort_values("Lag")
    
    print("ğŸ“Š èšåˆæ•°æ®é¢„è§ˆ:")
    print(df[['Experiment', 'Lag', 'DropRate', 'AvgLatency', 'Type']])
    
    # ä¿å­˜èšåˆæ•°æ®
    df.to_csv(os.path.join(OUTPUT_DIR, "aggregation_metrics.csv"), index=False)
    
    # --- å›¾è¡¨ 1: Drop Rate vs Lag ---
    plt.figure(figsize=(10, 6))
    types = df['Type'].unique()
    markers = ['o', 's', '^', 'D']
    
    for i, exp_type in enumerate(types):
        subset = df[df['Type'] == exp_type]
        plt.plot(subset['Lag'], subset['DropRate'] * 100, 
                 marker=markers[i % len(markers)], linestyle='-', linewidth=2, markersize=8, 
                 label=exp_type)
        
        for _, row in subset.iterrows():
            plt.text(row['Lag'], row['DropRate'] * 100 + 0.5, f"{row['DropRate']*100:.1f}%", ha='center')

    plt.title("Drop Rate vs Watermark Lag", fontsize=14)
    plt.xlabel("Watermark Lag (s)", fontsize=12)
    plt.ylabel("Drop Rate (%)", fontsize=12)
    plt.grid(True, linestyle='--', alpha=0.7)
    plt.legend()
    
    save_path = os.path.join(OUTPUT_DIR, "drop_rate_vs_lag.png")
    plt.savefig(save_path)
    print(f"ğŸ–¼ï¸ [1/2] ä¸¢å¼ƒç‡å›¾è¡¨å·²ä¿å­˜: {save_path}")
    
    # --- å›¾è¡¨ 2: Trade-off Analysis (Dual Axis) ---
    # åªç»˜åˆ¶ Tumbling Window (ä½œä¸ºä¸»è¦åˆ†æå¯¹è±¡) æˆ–è€…éƒ½ç”»
    # ä¸ºäº†æ¸…æ™°ï¼Œæˆ‘ä»¬é’ˆå¯¹æ¯ç§ç±»å‹ç”»ä¸€å¼ ï¼Œæˆ–è€…åªç”» Tumbling
    target_type = "Tumbling Window"
    subset = df[df['Type'] == target_type]
    
    if not subset.empty:
        fig, ax1 = plt.subplots(figsize=(10, 6))
        
        # å·¦è½´: ä¸¢å¼ƒç‡ (Drop Rate)
        color = 'tab:red'
        ax1.set_xlabel('Watermark Lag (s)', fontsize=12)
        ax1.set_ylabel('Drop Rate (%)', color=color, fontsize=12)
        l1, = ax1.plot(subset['Lag'], subset['DropRate'] * 100, color=color, marker='o', label='Drop Rate')
        ax1.tick_params(axis='y', labelcolor=color)
        ax1.grid(True, linestyle='--', alpha=0.5)

        # å³è½´: å»¶è¿Ÿ (Latency)
        ax2 = ax1.twinx()  
        color = 'tab:blue'
        ax2.set_ylabel('Average Latency (s)', color=color, fontsize=12)
        l2, = ax2.plot(subset['Lag'], subset['AvgLatency'], color=color, marker='s', linestyle='--', label='Latency')
        ax2.tick_params(axis='y', labelcolor=color)
        ax2.grid(False) # å³è½´ä¸ç”»ç½‘æ ¼ï¼Œé¿å…æ··ä¹±

        plt.title(f"Trade-off Analysis: Accuracy vs Latency ({target_type})", fontsize=14)
        
        # åˆå¹¶å›¾ä¾‹
        lines = [l1, l2]
        labels = [l.get_label() for l in lines]
        ax1.legend(lines, labels, loc='upper center')
        
        save_path_2 = os.path.join(OUTPUT_DIR, "tradeoff_analysis.png")
        plt.savefig(save_path_2)
        print(f"ğŸ–¼ï¸ [2/2] æƒè¡¡åˆ†æå›¾è¡¨å·²ä¿å­˜: {save_path_2}")
    else:
        print(f"âš ï¸ æ²¡æœ‰æ‰¾åˆ° {target_type} çš„æ•°æ®ï¼Œè·³è¿‡ Trade-off å›¾è¡¨")

if __name__ == "__main__":
    analyze_aggregation()
