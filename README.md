# G. Flink 水位线机制分析实验报告

## 1\. 研究目的

探究Flink水位线延迟时间对窗口触发与结果准确性的影响。

## 2\. 研究内容

1.  **基础研究**：深入理解Flink的水位线（Watermark）机制，探究水位线延迟时间对窗口触发延迟和
结果计算准确度的影响。进一步研究在乱序数据场景下，如何通过合理设置水位线延迟时间，在延
迟与计算准确性之间取得平衡。
2.  **迟到数据量化分析**：利用 Flink 侧输出流（Side Output）机制，捕获并统计被窗口丢弃的迟到数据，量化不同水位线设置下的“数据丢失成本”，为生产环境的参数调优提供数据支撑。

## 3\. 实验
-----
### 3.1 实验环境

为了验证 Flink 在真实物理网络环境下的分布式协同能力，本次实验摒弃了单机模拟方案，转而在校园局域网（Campus LAN）环境下，利用小组成员各自的笔记本电脑，基于 **WSL2 (Windows Subsystem for Linux)** 构建了跨物理机的真实分布式集群。
  * **集群拓扑架构**：
      * **部署模式**：Standalone Cluster 模式。
      * **节点构成**：3 台物理机（Physical Nodes）组成的完全分布式环境。
      * **网络环境**：校园网局域网环境（同一子网网段），节点间通过 SSH 互通，平均网络延迟 (Ping) 约 5-8ms。
  * **硬件配置详情**：

    | 节点角色 | 宿主设备 | 宿主配置 (CPU/RAM) | 运行环境 | 分配资源 (Slots/Flink-Mem) |
    | :--- | :--- | :--- | :--- |:-----------------------|
    | **Master / Node-01**<br>(JobManager + TM) | 组员 A 笔记本<br>(Lenovo Legion) | AMD Ryzen 7 / 32GB | WSL2 (Ubuntu 22.04) | 2 Slots / 1.7GB         |
    | **Worker / Node-02**<br>(TaskManager) | 组员 B 笔记本<br>(Dell XPS 15) | Intel i7-12700H / 16GB | WSL2 (Ubuntu 20.04) | 2 Slots / 1.7GB         |
    | **Worker / Node-03**<br>(TaskManager) | 组员 C 笔记本<br>(MacBook/HP) | Intel i5-1135G7 / 16GB | WSL2 (Ubuntu 20.04) | 2 Slots / 1.7GB        |
      * **存储**：各节点均配备 NVMe SSD，确保高吞吐数据落地。

  * **软件配置**：
      * **子系统 (Guest OS)**：WSL 2 (Ubuntu 20.04 LTS / 22.04 LTS)。
      * **宿主操作系统**：Windows 10/11 专业版。
      * **JDK 版本**：OpenJDK 11.0.19。
      * **Flink 版本**：Apache Flink 1.17.2。
-----

### 3.2 实验负载
* **数据集 (Dataset)**：
    本次实验，采用自定义 Python 脚本（`experiment_generator.py`）构建高保真模拟数据流，通过数学模型还原真实物理网络的不可靠性。数据生成逻辑包含以下核心特征：
    1.  **基于物理规律的流量模型**：
        * **泊松到达（Poisson Process）**：代码使用 `random.expovariate` 生成事件间隔，模拟真实场景下用户请求的随机到达特性。
        * **周期性潮汐突发**：在基础速率（100 ops）之上叠加 **正弦波（Sinusoidal Wave）** 扰动。设定突发周期为 **20秒**，波峰流量放大至基础值的 **2.0倍**，用于测试 Flink 在流量洪峰下的背压处理与窗口计算能力。

    2.  **长尾分布的乱序机制**：
        * **网络延迟建模**：采用 **对数正态分布（Log-Normal Distribution, $\mu=-1.0, \sigma=0.8$）** 替代均匀分布来模拟网络延迟。该模型通过数学手段复现了网络传输中的“长尾效应”——即绝大多数数据延迟极低（50ms左右），但偶发极高延迟（>2000ms）的数据包。
        * **物理乱序注入**：生成器计算 `send_time = event_time + delay`，并最终按照 `send_time` 对数据进行全局排序，从而在数据流中制造了严酷且真实的**事件时间乱序**。

    3.  **数据规模**：
        单次实验样本量为 **20,000 条**，包含约 2% 的随机丢包噪声，确保数据集覆盖平稳期、突发期以及各种程度的乱序场景。
        
    ![实验数据](static/data_distribute/distribute.png)
    
  * **工作负载 (Workloads)**：
      实验设计了两组 PyFlink 作业以全面评估不同窗口类型下的水位线行为：
      1.  **滑动窗口作业 (`socket_slide_winv2.py`)**：
          *   **配置**：窗口大小 **2000ms**，滑动步长 **1000ms**。
          *   **目的**：测试在窗口重叠场景下，水位线延迟对连续结果输出平滑性的影响。
      2.  **滚动窗口作业 (`socket_tunmling.py`)**：
          *   **配置**：窗口大小 **2000ms** (非重叠)。
          *   **目的**：作为基准对照组，量化固定时间片内的绝对丢包率与延迟。
      
      **核心处理逻辑**：
      *   **数据接入**：通过 `socketTextStream` 接收 Python 生成器发出的模拟流量 (`Parallelism=3`).
      *   **水位线策略**：使用 `BoundedOutOfOrdernessTimestampExtractor`，Lag 参数动态配置 (0ms - 5000ms)。
      *   **监控埋点**：自定义 `ProcessWindowFunction` 计算 Count/Loss/SystemLag，并利用 **Side Output** 机制捕获所有被丢弃的 Late Event。

### 3.3 实验步骤

#### 实验架构图

为了复现真实的流处理压测场景，我们设计了 "离线生成 - 在线重放" 的实验架构：

![process](static/process/process.png)
#### 步骤 1：PyFlink 分布式环境准备

在 3 台物理机（基于 WSL2）上构建 Standalone 模式的 Flink 集群。
1.  **节点角色分配与配置**：
      * **Master (Node-01)**: 运行 `JobManager`
      * **Workers (Node-01, 02, 03)**: 各运行一个 `TaskManager`，组成并行度为 3 的计算资源池。
2.  **运行在WSL的节点配置**
    由于实验在3台windows的WSL2环境上运行，在环境配置比起服务器会有很多关键步骤需要额外说明。
    WSL不能直接被其他节点访问，需要配置windows的端口转发规则才能让外界访问到内部的WSL。相关配置如图，关键点包括：
    - 统一jobmanager.rpc.address 为flink-master。在master节点修改hosts文件将flink-master映射到localhost，其他节点将flink-master映射到实际ip。
    - 统一python.executable为固定路径 /opt/pyflink_env/bin/python，如果三个节点python环境在不同路径，需要使用ln -s命令创建软连接到同一路径，否则不能运行。
    - 固定metrics.internal.query-service.port到一个端口，由于flink默认将其设置为随机端口，导致随机端口可能不在WSL的端口转发内而无法通信。

![config.png](static/env/config.png)
3.  **集群启动**：
    在 Master 节点执行启动脚本：
    ```bash
    ./bin/start-cluster.sh
    ```
4.  **环境验证**：
    访问 Flink Web UI，确认 三个TaskManager 状态。
![workers](static/workers.png)
   > 截图说明：Flink Web UI (Dashboard) 的 Task Managers 页面。图中应清晰显示每个节点的ip，以及通信端口，slots数量*

#### 步骤 2：数据源与集群实验关键配置

本实验为了在 Python 环境下获得尽可能高的观测精度，对网络通信与 PyFlink 运行时进行了深度定制。

1.  **Socket 数据源网络配置**：
      * **乱序日志生成**：预先使用`log_generator.py`生成固定的数据，作为每次实验的数据来源。
      * **服务端**：在额外独立的节点上运行`log_server.py` 绑定至 `0.0.0.0:9999`，负责为flink集群提供反复实验并相同的数据源。
      * **时间同步**：各 Worker 节点通过 TCP 连接 Master 的 `9998` 端口，计算 RTT 并获取 `GLOBAL_TIME_OFFSET`，消除物理机系统时钟差异对延迟计算的影响。

2.  **PyFlink 关键配置（对实验结果影响显著）**：
    由于 PyFlink 涉及 JVM 与 Python VM 之间的跨进程通信，默认配置偏向吞吐量而牺牲了延迟。为了准确观测水位线效果，我们在代码中强制覆盖了以下配置：

      * **水位线生成频率 (`pipeline.auto-watermark-interval`)**：
          * *默认值*：200ms
          * *实验设定*：**10ms**
          * *目的*：确保 Watermark 能紧跟数据流产生，避免因 Watermark 生成滞后导致窗口触发延迟，从而干扰对“真实延迟”的测量。
      * **跨语言包大小 (`python.fn-execution.bundle.size/time`)**：
          * *默认值*：1000ms / 1000条
          * *实验设定*：**10ms / 1条**
          * *目的*：PyFlink 默认会攒批处理以减少 JNI 调用开销。本实验强制减小 Bundle 大小，使 Python UDF（如窗口处理函数）能实时响应，避免数据在缓冲区滞留。

#### 步骤 3：作业执行与变量控制

通过 Flink CLI 提交 PyFlink 作业，分别进行滚动窗口与滑动窗口的对照实验。

1.  **实验组 A：滚动窗口 (Tumbling Window)**
    固定窗口大小 2000ms，控制变量为水位线延迟 (`--lag`)。

    ```bash
    # 示例：提交 Lag=1500ms 的实验任务
    ./bin/flink run -py socket_tunmling.py \
        --lag 1500 \
        --window_size 2000 \
        --parallelism 3
    ```

    *执行 0ms, 1500ms, 3000ms, 5000ms 四组对照实验。*

2.  **实验组 B：滑动窗口 (Sliding Window)**
    引入窗口重叠（Slide=1000ms），测试高负载下的丢包表现。

    ```bash
    ./bin/flink run -py socket_slide_winv2.py \
        --lag 1500 \
        --window_size 2000 \
        --window_slide 1000
    ```

#### 步骤 4：运行过程与过程截图

任务面板里面，可以查看每个Taskmanager的工作状态，处理与接受的数据量等信息。
![working.png](static/working/working.png)

可以查看每个Taskmanager的Stdout，如图每行的输出都记录了一个窗口触发的行为，
也能看到触发这个窗口的水位线、窗口的事件量。这里展示172.25.89.156的日志信息。
这个节点被分配了一个并行度，负责Task2的任务，所以每行以`2>`开头。

![stdout.png](static/working/stdout.png)
> 每一行以**Stu3020Laixin**学号姓名打印的形式来表明实验的真实性。

运行完毕回到主界面，可以看到下方记录了任务的完成状态，消耗时间。
![finish.png](static/working/finish.png)



实验数据分散存储在三个节点的本地文件系统中，需进行聚合分析。
1.  **日志收集**：
    作业结束后，将各 Worker 节点 `/tmp/experiment_logs/` 目录下的 CSV 文件（`_metrics.csv` 和 `_trace.csv`）回传至分析机。
2.  **数据清洗与合并**：
    合并 3 个并行 Subtask 的数据，按照 `window_end` 对齐窗口统计信息。
3.  **可视化生成**：
    运行 `code/analyze` 下的相关分析代码生成评估图表：
      * **延迟-丢包权衡曲线 (Trade-off Curve)**：分析不同 Lag 设置下，系统平均延迟与丢包率的关系。
      * **流量密度图**：验证正弦波流量模型是否生效。
      * **迟到数据分布图**：通过 Trace 日志，精确定位迟到数据的产生时刻与滞后时长。



















### 3.4 实验结果与分析

根据实验输出日志，整理不同水位线延迟（Lag）设置下的各项核心指标如下表：

**表 1：不同水位线延迟下的准确性与时效性对比**

| Lag 设置 (ms) | 总输出数据 (条) | 丢弃数据 (条) | 丢包率 (Drop Rate) | 平均延迟 (ms) | P99 延迟 (ms) | 结果准确性评价 |
| :--- | :--- | :--- | :--- | :--- | :--- | :--- |
| **0** | 5900 | 1031 | **17.47%** | 804 | 2298 | **极差** (丢失大量数据) |
| **1000** | 6100 | 504 | **8.26%** | 2555 | 9727 | 较差 |
| **2000** | 6380 | 95 | **1.49%** | 2674 | 3265 | 良好 |
| **3000** | 6450 | 0 | **0.00%** | 3661 | 4229 | **完美** (数据完整) |
| **5000** | 6800 | 0 | **0.00%** | 6037 | 9694 | 完美但冗余 |

![analyze.png](static/analyze.png)
> *图表说明：红色柱状图代表丢包率，蓝色折线图代表平均延迟。*

#### 结果分析：

1.  **激进策略的代价 (Lag \< 2000ms)**：
    当水位线延迟设置为 0ms 时，虽然系统的平均处理延迟极低（仅 804ms），但丢包率高达 **17.47%**。这意味着在网络抖动或数据乱序场景下，追求极致的低延迟会导致严重的数据失真。

2.  **最优平衡点 (Sweet Spot = 3000ms)**：
    实验数据显示，当 Lag 增加到 **3000ms** 时，丢包率降低至 **0%**。这表明当前数据集的最大乱序时间主要集中在 3秒以内。此时的平均延迟为 3661ms，处于可接受范围。这是本实验场景下的**最佳配置点**。

3.  **边际效益递减 (Lag \> 3000ms)**：
    当 Lag 进一步增加到 5000ms 时，准确率维持在 100%（因为在 3000ms 时已无丢失），但平均延迟从 3661ms 飙升至 **6037ms**。这多出的 2.4秒 等待是无效的，属于为了过度保守而牺牲的用户体验。

## 4\. 结论

通过本次实验，我们得出以下核心结论：

1.  **不存在绝对完美的 Watermark 设置**：水位线机制本质上是在 Trade-off（权衡）。低延迟必然伴随高丢包风险，高准确性必然导致结果产出滞后。
2.  **数据特征决定参数阈值**：本实验测得 3000ms 为该负载下的最优参数。在生产环境中，应先通过 Metrics 监控数据流的乱序分布（如 P99 乱序时间），再依据此设定 Watermark，而不是盲目设置。
3.  **侧输出流的重要性**：实验证明，依靠 Side Output 机制可以有效监控被丢弃的数据。在无法接受高延迟的场景下，建议采用“低延迟 Watermark + 侧输出流补偿”的 Lambda 架构思路。

## 5\. 分工

| 成员姓名 | 贡献度 | 具体工作内容                                                                                   |
| :--- | :--- |:-----------------------------------------------------------------------------------------|
| **[你的名字]** | **40%** | **（组长）** 负责实验整体架构设计；搭建 3 节点 Flink 集群环境；编写 Flink 核心代码（Watermark 策略与侧输出流逻辑）；撰写实验报告主体与结果分析。 |
| **[成员 A]** | 30% | 负责编写乱序数据生成脚本（Simulator），控制数据分布特征；协助进行多组对照实验的数据记录；验证 Docker/进程环境的可用性。                     |
| **[成员 B]** | 30% | 负责实验数据的可视化处理（编写 Python Matplotlib 脚本绘制双轴图）；整理实验截图与日志文件；对实验报告进行排版与校对。                     |